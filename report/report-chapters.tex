\section{Introduction and Motivation}
Twitter, as any other social network and blog, is a constant source of unstructured data that, if processed in the right way, can be leveraged to obtain valuable insights. Due to this reason, lots of companies have started to collect this huge amount of data in order to perform in-depth analysis; many of them have initiated to perform sentiment analysis to check customers satisfaction with respect to their products. According to upGrad \cite{upGrad}, Big Data can help create pioneering breakthroughs for organizations that know how to use it correctly.

A challenging aspect in Big Data analysis is to extract valuable insights that can drive business strategies and decisions. In this context, Twitter plays a crucial role during the information retrieval phase: millions of people publish everyday short messages, hereafter tweets, that often contain their desires or demands. The aim of many companies is to exploit these tweets in order to catch common issues or demands to guide business strategies. These insights, according to upGrad \cite{upGrad}, can be used to develop new products/services, improve marketing techniques, optimize customer service, improve employee productivity and find radical ways to expand brand outreach.

In addition, organizations aim also to intercept occasional issues or demands that are not constant over time but are very popular in a bounded period of time. Catching this kind of insights, permits companies to better address their business short-term decision-making phase. According to Ben Ridler \cite{customer-satistaction}, a business owner ability to effectively deal with customer complaints provides a great opportunity to turn dissatisfied customers into active promoters of the business.

Nowadays there are lots of datasets that group together even millions of tweets and many of them are easily and freely accessible by anyone through internet. Despite the fact that many of those datasets contain unusable data that force us to pre-process them, companies can elaborate those tweets to achieve their business goals.

\section{Related work}


\section{Problem statement}
In order to achieve the above-mentioned goal (i.e., identify consistent topic in time in tweets), I have used a public available dataset that groups more than 300.000 tweets that contain the hashtag \textit{\#covid19} \cite{covid19-tweets-dataset}. As many other datasets composed of unstructured data dumped from a social network such as Twitter, the dataset I used has lots of fields that characterize each tweet (e.g., publisher's username, location and account information, text of the message, etc.). 

To identify consistent topics in time using those tweets, I only need the date of the publication of each of them and the relative text. In other words, in my working environment a tweet is defined as a tuple composed by the following fields:
\begin{itemize}
	\item \textbf{date}: the date of the tweet publication, expressed as an integer value that represents the number of seconds that have elapsed since the midnight of 1\textsuperscript{st} January 1970;
	\item \textbf{text}: the text of the tweet represented as a list of words. This list is obtained splitting the source text using the blank character " " as separator.
\end{itemize}

Therefore, in order to obtain the formal model of this problem, I define the following sets:
\begin{description}
	\item[TWEET] = the set of tweets, defined as $\mathrm{TIMESTAMP} \times \mathrm{TEXT}$ where $\mathrm{TIMESTAMP} \subset \mathbb{N}_{\geq 0}$, $\mathrm{TEXT} = \{x | x \in \Sigma^*\}$ and $\Sigma$ is the alphabet;
	\item[THRESHOLD] = the set of all the possible thresholds to identify frequent terms in time, defined as a subset of $\mathbb{N}_{\geq 0}$
\end{description}

\noindent The aim is to model an utility function \textit{f} defined as
\begin{center}
	\textit{f}: $\mathrm{TWEET} \times \mathrm{THRESHOLD} \mapsto \mathrm{TOPIC}$
\end{center}
where $\mathrm{TOPIC} = \{x | x \in \Sigma^*\}$ and $\Sigma$ is the alphabet. In other words, $\mathrm{TOPIC}$ is the set of all the possible trending topics over time.

\section{Solution}


\section{Implementation}


\section{Dataset}


\section{Experimental evaluation}
